{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageai\n",
      "  Using cached https://files.pythonhosted.org/packages/63/30/35d03408e14c4e768f8e4c04c9702205b0946f20f693f2e9cc0be4fe8910/imageai-2.1.4-py3-none-any.whl\n",
      "Collecting opencv-python\n",
      "  Downloading https://files.pythonhosted.org/packages/dc/54/a6b7727c67d4e14194549a9e1a1acd7902ebae2f4a688d84b658ae40b5fb/opencv_python-4.1.0.25-cp36-cp36m-win_amd64.whl (37.3MB)\n",
      "Requirement already satisfied: h5py in c:\\users\\neonalliance\\anaconda3\\lib\\site-packages (from imageai) (2.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\neonalliance\\anaconda3\\lib\\site-packages (from imageai) (1.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\neonalliance\\anaconda3\\lib\\site-packages (from imageai) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\neonalliance\\anaconda3\\lib\\site-packages (from imageai) (1.14.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\neonalliance\\anaconda3\\lib\\site-packages (from imageai) (5.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\neonalliance\\anaconda3\\lib\\site-packages (from h5py->imageai) (1.11.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\neonalliance\\anaconda3\\lib\\site-packages (from matplotlib->imageai) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\neonalliance\\anaconda3\\lib\\site-packages (from matplotlib->imageai) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\neonalliance\\anaconda3\\lib\\site-packages (from matplotlib->imageai) (2.7.3)\n",
      "Requirement already satisfied: pytz in c:\\users\\neonalliance\\anaconda3\\lib\\site-packages (from matplotlib->imageai) (2018.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\neonalliance\\anaconda3\\lib\\site-packages (from matplotlib->imageai) (1.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\neonalliance\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->imageai) (39.1.0)\n",
      "Installing collected packages: imageai, opencv-python\n",
      "Successfully installed imageai-2.1.4 opencv-python-4.1.0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install imageai opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neonalliance\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import VideoObjectDetection, ObjectDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detector = ObjectDetection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detector.setModelTypeAsYOLOv3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detector.setModelPath('./Downloads/yolo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detector.loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'handbag',\n",
       "  'percentage_probability': 61.32422685623169,\n",
       "  'box_points': (239, 317, 279, 368)},\n",
       " {'name': 'handbag',\n",
       "  'percentage_probability': 68.42808723449707,\n",
       "  'box_points': (788, 319, 827, 379)},\n",
       " {'name': 'traffic light',\n",
       "  'percentage_probability': 50.40328502655029,\n",
       "  'box_points': (509, 109, 519, 128)},\n",
       " {'name': 'traffic light',\n",
       "  'percentage_probability': 53.198033571243286,\n",
       "  'box_points': (475, 155, 485, 172)},\n",
       " {'name': 'traffic light',\n",
       "  'percentage_probability': 54.2589545249939,\n",
       "  'box_points': (298, 114, 309, 131)},\n",
       " {'name': 'traffic light',\n",
       "  'percentage_probability': 54.63480353355408,\n",
       "  'box_points': (327, 142, 336, 154)},\n",
       " {'name': 'traffic light',\n",
       "  'percentage_probability': 62.4722957611084,\n",
       "  'box_points': (220, 125, 232, 146)},\n",
       " {'name': 'traffic light',\n",
       "  'percentage_probability': 65.69246053695679,\n",
       "  'box_points': (719, 119, 734, 145)},\n",
       " {'name': 'traffic light',\n",
       "  'percentage_probability': 66.96033477783203,\n",
       "  'box_points': (734, 115, 751, 145)},\n",
       " {'name': 'traffic light',\n",
       "  'percentage_probability': 67.75937080383301,\n",
       "  'box_points': (609, 124, 622, 144)},\n",
       " {'name': 'traffic light',\n",
       "  'percentage_probability': 68.30267310142517,\n",
       "  'box_points': (384, 140, 391, 155)},\n",
       " {'name': 'traffic light',\n",
       "  'percentage_probability': 69.54724192619324,\n",
       "  'box_points': (278, 120, 288, 139)},\n",
       " {'name': 'traffic light',\n",
       "  'percentage_probability': 74.33043122291565,\n",
       "  'box_points': (480, 146, 489, 162)},\n",
       " {'name': 'traffic light',\n",
       "  'percentage_probability': 76.5586793422699,\n",
       "  'box_points': (352, 146, 358, 157)},\n",
       " {'name': 'traffic light',\n",
       "  'percentage_probability': 82.35667943954468,\n",
       "  'box_points': (73, 37, 102, 98)},\n",
       " {'name': 'traffic light',\n",
       "  'percentage_probability': 84.3647837638855,\n",
       "  'box_points': (526, 109, 537, 130)},\n",
       " {'name': 'truck',\n",
       "  'percentage_probability': 60.496461391448975,\n",
       "  'box_points': (427, 197, 517, 274)},\n",
       " {'name': 'truck',\n",
       "  'percentage_probability': 89.26662802696228,\n",
       "  'box_points': (714, 208, 824, 291)},\n",
       " {'name': 'bus',\n",
       "  'percentage_probability': 79.5667290687561,\n",
       "  'box_points': (325, 179, 403, 287)},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 59.27854776382446,\n",
       "  'box_points': (180, 222, 256, 269)},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 61.93699240684509,\n",
       "  'box_points': (81, 169, 759, 298)},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 62.23450303077698,\n",
       "  'box_points': (664, 237, 720, 285)},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 64.68958258628845,\n",
       "  'box_points': (115, 253, 153, 310)},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 64.82412815093994,\n",
       "  'box_points': (513, 227, 561, 264)},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 81.00961446762085,\n",
       "  'box_points': (533, 241, 597, 288)},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 89.77918028831482,\n",
       "  'box_points': (336, 257, 396, 312)},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 93.23936700820923,\n",
       "  'box_points': (284, 223, 325, 267)},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 96.09721302986145,\n",
       "  'box_points': (439, 249, 503, 307)},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 96.78391218185425,\n",
       "  'box_points': (214, 252, 283, 310)},\n",
       " {'name': 'car',\n",
       "  'percentage_probability': 98.26213717460632,\n",
       "  'box_points': (0, 288, 82, 404)},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 60.35776138305664,\n",
       "  'box_points': (200, 276, 232, 350)},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 63.78521919250488,\n",
       "  'box_points': (560, 277, 592, 375)},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 65.4261827468872,\n",
       "  'box_points': (155, 271, 187, 363)},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 78.70669364929199,\n",
       "  'box_points': (635, 283, 678, 405)},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 79.33048009872437,\n",
       "  'box_points': (171, 271, 202, 362)},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 79.50442433357239,\n",
       "  'box_points': (528, 270, 559, 354)},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 96.3079035282135,\n",
       "  'box_points': (685, 282, 737, 387)},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 96.4629590511322,\n",
       "  'box_points': (796, 280, 850, 441)},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 97.73489236831665,\n",
       "  'box_points': (283, 265, 353, 446)},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 98.07281494140625,\n",
       "  'box_points': (376, 276, 425, 386)},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 98.25769066810608,\n",
       "  'box_points': (736, 278, 792, 394)},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 98.28057885169983,\n",
       "  'box_points': (194, 279, 303, 443)},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 98.541921377182,\n",
       "  'box_points': (487, 262, 537, 385)},\n",
       " {'name': 'person',\n",
       "  'percentage_probability': 99.07916188240051,\n",
       "  'box_points': (564, 256, 666, 442)}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_detector.detectObjectsFromImage(input_image='./Desktop/nycstreet.jpg',\n",
    "output_image_path = './Desktop/nycstreetyolom32b5.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
